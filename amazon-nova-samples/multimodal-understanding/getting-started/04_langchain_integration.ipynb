{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d932ae5-c2b1-4de8-865f-aa28509c33ee",
   "metadata": {},
   "source": [
    "## Langchain Integration for Nova\n",
    "\n",
    "To aid in the development of applications with Nova models; Langchain support has been added for multimodal and agentic workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7419d32-d280-41a9-922a-c210eae828b9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0cdbc4-698b-4992-9468-a3152d40edd0",
   "metadata": {},
   "source": [
    "#### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e090009-940a-4f23-a9b9-141542376c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-aws 0.1.17 requires boto3<1.35.0,>=1.34.131, but you have boto3 1.35.79 which is incompatible.\n",
      "langchain-aws 0.1.17 requires langchain-core<0.3,>=0.2.33, but you have langchain-core 0.3.24 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain_community faiss_cpu pypdf --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d9169b-3f39-465a-9f80-50976b3510dd",
   "metadata": {},
   "source": [
    "**Note**: Micro can be used for text understanding use case and Lite and Pro for multimodal understanding use cases.\n",
    "\n",
    "- Nova Micro: \"us.amazon.nova-micro-v1:0\"\n",
    "- Nova Lite: \"us.amazon.nova-lite-v1:0\"\n",
    "- Nova Pro: \"us.amazon.nova-pro-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42115341-e153-45f8-9d3e-d2971f722c4b",
   "metadata": {},
   "source": [
    "## Model Invocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e03481-0e86-475d-b84a-dba277ba7eb4",
   "metadata": {},
   "source": [
    "#### Text Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f0bb9a-df70-484e-9823-1b474363678b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hoang Kha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\langchain_aws\\chat_models\\__init__.py:1: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_aws.chat_models.bedrock import BedrockChat, ChatBedrock\n",
      "C:\\Users\\Hoang Kha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pydantic\\_internal\\_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "ename": "SchemaError",
     "evalue": "Invalid Schema:\nmodel.config.extra_fields_behavior\n  Input should be 'allow', 'forbid' or 'ignore' [type=literal_error, input_value=<Extra.forbid: 'forbid'>, input_type=Extra]\n    For further information visit https://errors.pydantic.dev/2.9/v/literal_error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSchemaError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_aws\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatBedrockConverse\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n\u001b[0;32m      4\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatBedrockConverse(\n\u001b[0;32m      5\u001b[0m     model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus.amazon.nova-lite-v1:0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\langchain_aws\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_aws\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BedrockChat, ChatBedrock, ChatBedrockConverse\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_aws\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BedrockEmbeddings\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_aws\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeptuneAnalyticsGraph, NeptuneGraph\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\langchain_aws\\chat_models\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_aws\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbedrock\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BedrockChat, ChatBedrock\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_aws\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbedrock_converse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatBedrockConverse\n\u001b[0;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBedrockChat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatBedrock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatBedrockConverse\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\langchain_aws\\chat_models\\bedrock.py:42\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseTool\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TypeBaseModel, is_basemodel_subclass\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_aws\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbedrock_converse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatBedrockConverse\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_aws\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunction_calling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     44\u001b[0m     ToolsOutputParser,\n\u001b[0;32m     45\u001b[0m     _lc_tool_calls_to_anthropic_tool_use_blocks,\n\u001b[0;32m     46\u001b[0m     convert_to_anthropic_tool,\n\u001b[0;32m     47\u001b[0m     get_system_message,\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_aws\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbedrock\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     BedrockBase,\n\u001b[0;32m     51\u001b[0m     _combine_generation_info_for_llm_result,\n\u001b[0;32m     52\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\langchain_aws\\chat_models\\bedrock_converse.py:58\u001b[0m\n\u001b[0;32m     54\u001b[0m _BM \u001b[38;5;241m=\u001b[39m TypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_BM\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39mBaseModel)\n\u001b[0;32m     55\u001b[0m _DictOrPydanticClass \u001b[38;5;241m=\u001b[39m Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Type[_BM], Type]\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mChatBedrockConverse\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mBaseChatModel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Bedrock chat model integration built on the Bedrock converse API.\u001b[39;49;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;43;03m    This implementation will eventually replace the existing ChatBedrock implementation\u001b[39;49;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;43;03m             'metrics': {'latencyMs': 1290}}\u001b[39;49;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: E501\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mAny\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mField\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#: :meta private:\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pydantic\\_internal\\_model_construction.py:224\u001b[0m, in \u001b[0;36mModelMetaclass.__new__\u001b[1;34m(mcs, cls_name, bases, namespace, __pydantic_generic_metadata__, __pydantic_reset_parent_namespace__, _create_model_module, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_wrapper\u001b[38;5;241m.\u001b[39mfrozen \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__hash__\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m namespace:\n\u001b[0;32m    222\u001b[0m     set_default_hash_func(\u001b[38;5;28mcls\u001b[39m, bases)\n\u001b[1;32m--> 224\u001b[0m \u001b[43mcomplete_model_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcls_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraise_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtypes_namespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypes_namespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_model_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_create_model_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m# If this is placed before the complete_model_class call above,\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# the generic computed fields return type is set to PydanticUndefined\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_computed_fields \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39minfo \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_decorators__\u001b[38;5;241m.\u001b[39mcomputed_fields\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pydantic\\_internal\\_model_construction.py:587\u001b[0m, in \u001b[0;36mcomplete_model_class\u001b[1;34m(cls, cls_name, config_wrapper, raise_errors, types_namespace, create_model_module)\u001b[0m\n\u001b[0;32m    584\u001b[0m core_config \u001b[38;5;241m=\u001b[39m config_wrapper\u001b[38;5;241m.\u001b[39mcore_config(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[43mgen_schema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m gen_schema\u001b[38;5;241m.\u001b[39mCollectedInvalid:\n\u001b[0;32m    589\u001b[0m     set_model_mocks(\u001b[38;5;28mcls\u001b[39m, cls_name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pydantic\\_internal\\_generate_schema.py:595\u001b[0m, in \u001b[0;36mGenerateSchema.clean_schema\u001b[1;34m(self, schema)\u001b[0m\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCollectedInvalid()\n\u001b[0;32m    594\u001b[0m schema \u001b[38;5;241m=\u001b[39m _discriminated_union\u001b[38;5;241m.\u001b[39mapply_discriminators(schema)\n\u001b[1;32m--> 595\u001b[0m schema \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_core_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m schema\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pydantic\\_internal\\_core_utils.py:570\u001b[0m, in \u001b[0;36mvalidate_core_schema\u001b[1;34m(schema)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPYDANTIC_SKIP_VALIDATING_CORE_SCHEMAS\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m schema\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_validate_core_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mSchemaError\u001b[0m: Invalid Schema:\nmodel.config.extra_fields_behavior\n  Input should be 'allow', 'forbid' or 'ignore' [type=literal_error, input_value=<Extra.forbid: 'forbid'>, input_type=Extra]\n    For further information visit https://errors.pydantic.dev/2.9/v/literal_error"
     ]
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model_id=\"us.amazon.nova-lite-v1:0\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"Provide three alternative song titles for a given user title\"),\n",
    "    (\"user\", \"Teardrops on My Guitar\"),\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(f\"Request ID: {response.id}\")\n",
    "response.pretty_print()\n",
    "\n",
    "\n",
    "# Here we can pass the chat history to the model to ask follow up questions\n",
    "multi_turn_messages = [\n",
    "    *messages,\n",
    "    response,\n",
    "    HumanMessage(content=\"Select your favorite and tell me why\"),\n",
    "]\n",
    "\n",
    "response = llm.invoke(multi_turn_messages)\n",
    "print(f\"\\n\\nRequest ID: {response.id}\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e2084-5240-4a4f-a2e5-56ed303fb5ac",
   "metadata": {},
   "source": [
    "#### Image Understanding\n",
    "\n",
    "You are able to pass various media types to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766bbdff-bdf5-4d5d-ab5b-a324622d40f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "image_path = \"media/sunset.png\"\n",
    "Image(filename=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e552f1-40c1-4921-9668-44da4e079aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    binary_data = image_file.read()\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"image\": {\"format\": \"png\", \"source\": {\"bytes\": binary_data}}},\n",
    "        {\"text\": \"Provide a summary of this photo\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = llm.invoke([message])\n",
    "print(f\"\\n\\nRequest ID: {response.id}\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884decd3-7ea1-47b4-bff4-188d412664fb",
   "metadata": {},
   "source": [
    "#### Video Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee15b13-6064-4a31-98a1-d067edb8bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"media/cooking-quesadilla.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e61fc-f354-4421-a46d-522d10d1a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "with open(video_path, \"rb\") as video_file:\n",
    "    binary_data = video_file.read()\n",
    "\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"video\": {\"format\": \"mp4\", \"source\": {\"bytes\": binary_data}}},\n",
    "        {\"type\": \"text\", \"text\": \"Describe the following video\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = llm.invoke([message])\n",
    "print(f\"\\n\\nRequest ID: {response.id}\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace6d076-16dd-4285-b8cc-862f1c6e0e0d",
   "metadata": {},
   "source": [
    "#### Streaming\n",
    "\n",
    "Streaming is also supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1db1f-01a4-43da-af72-a3a50954a8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = llm | StrOutputParser()\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an author with experience writing creative novels\"),\n",
    "    HumanMessage(\n",
    "        content=\"Write an outlin for a novel about a wizard named Theodore graduating from college\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "for chunk in chain.stream(messages):\n",
    "    print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fb633d-a49c-4a4b-9869-0fdb995ca8dc",
   "metadata": {},
   "source": [
    "## Agent Workflows\n",
    "\n",
    "The Nova model is capable of handling tool calling and agentic workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dbb61d-ec8e-489a-a012-fad5c6a35341",
   "metadata": {},
   "source": [
    "#### Binding Tools\n",
    "\n",
    "When using a model for tool calling you can take advantage of the bind tools method. This will pass a formatted tool config to the model. We recommend when taking advantage of tool calling or agentic workflows to use greedy decoding values. This means temperature=1, topP=1, topK=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288f6941-ebc7-45b0-b6dc-9fe201cc2197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [multiply]\n",
    "\n",
    "llm_with_tools = ChatBedrockConverse(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    additional_model_request_fields={\n",
    "        \"inferenceConfig\": {\n",
    "            \"topK\": 1\n",
    "        }\n",
    "    },\n",
    ").bind_tools(tools)\n",
    "\n",
    "response = llm_with_tools.invoke([(\"user\", \"What is 8*8\")])\n",
    "\n",
    "print(\"[Model Response]\\n\")\n",
    "print(response.content)\n",
    "\n",
    "print(\"\\n[Tool Calls]\\n\")\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6f0cca-d9d8-4b1e-93f5-e3b8321ea754",
   "metadata": {},
   "source": [
    "#### Tool Calling Agents\n",
    "\n",
    "For full workflows you can take advantage of custom parsers that will intercept outputs of the stream and allow you to invoke tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e07d53-8381-44cb-a7de-b6e3ffcd1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool, AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [multiply]\n",
    "\n",
    "llm_with_tools = ChatBedrockConverse(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    additional_model_request_fields={\n",
    "        \"inferenceConfig\": {\n",
    "            \"topK\": 1\n",
    "        }\n",
    "    },\n",
    ").bind_tools(tools)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"What is 2*2?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e1ebb6",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "Structured output is a great way to force the model to return in a specific way. We use Greedy Decoding params here for more determinist results (Temperature = 1, Top P = 1, Top K = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7841a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"A joke to respond to the user\"\"\"\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"us.amazon.nova-lite-v1:0\",\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    additional_model_request_fields={\n",
    "        \"inferenceConfig\": {\n",
    "            \"topK\": 1\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a9df94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5f9782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
